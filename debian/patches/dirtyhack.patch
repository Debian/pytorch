Description: The elegant patching work is based on the master branch
    https://github.com/pytorch/pytorch/issues/14699
  And we will be able to use that solution in the next upstream release.
  I don't want to rebase my patches back to this version, so let's go with a fast, yet dirty hack.
Author: Mo Zhou
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -116,10 +116,11 @@
 # Note to developers: if you add an option below, make sure you also add it to
 # cmake/Summary.cmake so that the summary prints out the option values.
 include(CMakeDependentOption)
+set(CMAKE_VERBOSE_MAKEFILE ON)
 option(ATEN_NO_TEST "Do not build ATen test binaries" OFF)
 option(BUILD_BINARY "Build C++ binaries" OFF)
 option(BUILD_DOCS "Build Caffe2 documentation" OFF)
-option(BUILD_CUSTOM_PROTOBUF "Build and use Caffe2's own protobuf under third_party" ON)
+option(BUILD_CUSTOM_PROTOBUF "Build and use Caffe2's own protobuf under third_party" OFF)
 option(BUILD_PYTHON "Build Python binaries" ON)
 option(BUILD_CAFFE2_OPS "Build Caffe2 operators" ON)
 option(BUILD_SHARED_LIBS "Build libcaffe2.so" ON)
@@ -168,7 +169,7 @@
     USE_SYSTEM_NCCL "Use system-wide NCCL" OFF
     "USE_NCCL" OFF)
 option(USE_NNAPI "Use NNAPI" OFF)
-option(USE_NNPACK "Use NNPACK" ON)
+option(USE_NNPACK "Use NNPACK" OFF)
 cmake_dependent_option(
     USE_NUMA "Use NUMA. Only available on Linux." ON
     "LINUX" OFF)
@@ -181,13 +182,13 @@
 option(USE_OPENCV "Use OpenCV" OFF)
 option(USE_OPENMP "Use OpenMP for parallel code" ON)
 option(USE_PROF "Use profiling" OFF)
-option(USE_QNNPACK "Use QNNPACK (quantized 8-bit operators)" ON)
+option(USE_QNNPACK "Use QNNPACK (quantized 8-bit operators)" OFF)
 option(USE_PYTORCH_QNNPACK "Use ATen/QNNPACK (quantized 8-bit operators)" ON)
 option(USE_REDIS "Use Redis" OFF)
 option(USE_ROCKSDB "Use RocksDB" OFF)
 option(USE_SNPE "Use Qualcomm's SNPE library" OFF)
 option(USE_SYSTEM_EIGEN_INSTALL
-    "Use system Eigen instead of the one under third_party" OFF)
+	"Use system Eigen instead of the one under third_party" ON)
 option(USE_TENSORRT "Using Nvidia TensorRT library" OFF)
 option(USE_VULKAN "Use Vulkan GPU backend" OFF)
 option(USE_VULKAN_WRAPPER "Use Vulkan wrapper" ON)
@@ -214,7 +215,7 @@
     "USE_DISTRIBUTED" OFF)
 option(USE_TBB "Use TBB" OFF)
 option(ONNX_ML "Enable traditional ONNX ML API." ON)
-option(HAVE_SOVERSION "Whether to add SOVERSION to the shared objects" OFF)
+option(HAVE_SOVERSION "Whether to add SOVERSION to the shared objects" ON)
 
 # Linux distributions do not want too many embedded sources, in that sense we
 # need to be able to build pytorch with an (almost) empty third_party
@@ -233,6 +234,7 @@
 option(USE_SYSTEM_BENCHMARK "Use system-provided google benchmark." OFF)
 option(USE_SYSTEM_ONNX "Use system-provided onnx." OFF)
 option(USE_SYSTEM_XNNPACK "Use system-provided xnnpack." OFF)
+option(USE_SYSTEM_TENSORPIPE "Use system-provided tensorpipe." OFF)
 if(USE_SYSTEM_LIBS)
   set(USE_SYSTEM_CPUINFO ON)
   set(USE_SYSTEM_SLEEF ON)
@@ -246,11 +248,14 @@
   set(USE_SYSTEM_BENCHMARK ON)
   set(USE_SYSTEM_ONNX ON)
   set(USE_SYSTEM_XNNPACK ON)
+  set(USE_SYSTEM_TENSORPIPE ON)
 endif()
 
 # Used when building Caffe2 through setup.py
 option(BUILDING_WITH_TORCH_LIBS "Tell cmake if Caffe2 is being built alongside torch libs" ON)
 
+set(GOOGLETEST_SOURCE_DIR "/usr/src/googletest")
+
 # /Z7 override option
 # When generating debug symbols, CMake default to use the flag /Zi.
 # However, it is not compatible with sccache. So we rewrite it off.
--- a/cmake/Dependencies.cmake
+++ b/cmake/Dependencies.cmake
@@ -10,10 +10,10 @@
 set(CMAKE_SKIP_BUILD_RPATH  FALSE)
 # Don't use the install-rpath during the build phase
 set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE)
-set(CMAKE_INSTALL_RPATH "${_rpath_portable_origin}")
+set(CMAKE_INSTALL_RPATH "")
 # Automatically add all linked folders that are NOT in the build directory to
 # the rpath (per library?)
-set(CMAKE_INSTALL_RPATH_USE_LINK_PATH TRUE)
+set(CMAKE_INSTALL_RPATH_USE_LINK_PATH FALSE)
 
  # UBSAN triggers when compiling protobuf, so we need to disable it.
 set(UBSAN_FLAG "-fsanitize=undefined")
@@ -1286,7 +1286,12 @@
   endif()
 endif()
 
-if(USE_DISTRIBUTED AND USE_TENSORPIPE)
+if(USE_DISTRIBUTED AND USE_TENSORPIPE AND USE_SYSTEM_TENSORPIPE)
+	add_library(tensorpipe SHARED IMPORTED)
+	find_library(TENSORPIPE_LIBRARY tensorpipe)
+	set_property(TARGET tensorpipe PROPERTY IMPORTED_LOCATION "${TENSORPIPE_LIBRARY}")
+	list(APPEND Caffe2_DEPENDENCY_LIBS tensorpipe)
+elseif(USE_DISTRIBUTED AND USE_TENSORPIPE)
   if(MSVC)
     message(WARNING "Tensorpipe cannot be used on Windows.")
   else()
@@ -1382,7 +1387,7 @@
   if(NOT USE_SYSTEM_ONNX)
     add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/../third_party/onnx EXCLUDE_FROM_ALL)
   endif()
-  add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/../third_party/foxi EXCLUDE_FROM_ALL)
+  add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/../debian/foxi EXCLUDE_FROM_ALL)
 
   add_definitions(-DONNX_NAMESPACE=${ONNX_NAMESPACE})
   if(NOT USE_SYSTEM_ONNX)
@@ -1719,7 +1724,7 @@
 # End ATen checks
 #
 
-add_subdirectory(${CMAKE_SOURCE_DIR}/third_party/fmt)
+#add_subdirectory(${CMAKE_SOURCE_DIR}/third_party/fmt)
 
 # Disable compiler feature checks for `fmt`.
 #
@@ -1728,6 +1733,6 @@
 # CMAKE_CXX_FLAGS in ways that break feature checks. Since we already know
 # `fmt` is compatible with a superset of the compilers that PyTorch is, it
 # shouldn't be too bad to just disable the checks.
-set_target_properties(fmt-header-only PROPERTIES INTERFACE_COMPILE_FEATURES "")
+#set_target_properties(fmt-header-only PROPERTIES INTERFACE_COMPILE_FEATURES "")
 
-list(APPEND Caffe2_DEPENDENCY_LIBS fmt::fmt-header-only)
+#list(APPEND Caffe2_DEPENDENCY_LIBS fmt::fmt-header-only)
--- a/aten/src/ATen/native/quantized/cpu/qnnpack/CMakeLists.txt
+++ b/aten/src/ATen/native/quantized/cpu/qnnpack/CMakeLists.txt
@@ -298,7 +298,7 @@
 set_target_properties(pytorch_qnnpack PROPERTIES PUBLIC_HEADER include/qnnpack_func.h)
 
 # ---[ Configure clog
-if(NOT TARGET clog)
+if(NOT TARGET clog AND NOT USE_SYSTEM_CLOG)
   set(CLOG_BUILD_TESTS OFF CACHE BOOL "")
   set(CLOG_RUNTIME_TYPE "${CPUINFO_RUNTIME_TYPE}" CACHE STRING "")
   add_subdirectory(
@@ -306,6 +306,9 @@
     "${CONFU_DEPENDENCIES_BINARY_DIR}/clog")
   # We build static version of clog but a dynamic library may indirectly depend on it
   set_property(TARGET clog PROPERTY POSITION_INDEPENDENT_CODE ON)
+elseif(NOT TARGET clog and USE_SYSTEM_CLOG)
+  add_library(clog STATIC ${CMAKE_SOURCE_DIR}/debian/clog/src/clog.c
+	${CMAKE_SOURCE_DIR}/debian/clog/include/clog.h)
 endif()
 target_link_libraries(pytorch_qnnpack PUBLIC clog)
 
--- a/tools/setup_helpers/cmake.py
+++ b/tools/setup_helpers/cmake.py
@@ -341,5 +341,5 @@
         if IS_WINDOWS and not USE_NINJA:  # We are likely using msbuild here
             build_args += ['--', '/p:CL_MPCount={}'.format(max_jobs)]
         else:
-            build_args += ['--', '-j', max_jobs]
+            build_args += ['--', '-j', max_jobs, '-v']
         self.run(build_args, my_env)
--- a/modules/module_test/CMakeLists.txt
+++ b/modules/module_test/CMakeLists.txt
@@ -10,6 +10,7 @@
   add_library(
       caffe2_module_test_dynamic
       ${CMAKE_CURRENT_SOURCE_DIR}/module_test_dynamic.cc)
+  set_target_properties(caffe2_module_test_dynamic PROPERTIES VERSION 1 SOVERSION 1)
 
   if(HAVE_SOVERSION)
     set_target_properties(caffe2_module_test_dynamic PROPERTIES
--- a/torch/CMakeLists.txt
+++ b/torch/CMakeLists.txt
@@ -81,10 +81,16 @@
 
 list(APPEND TORCH_PYTHON_INCLUDE_DIRECTORIES ${LIBSHM_SRCDIR})
 
+if(NOT FMT_LIBRARY)
+	add_library(fmt STATIC IMPORTED)
+	find_library(FMT_LIBRARY fmt)
+	set_property(TARGET fmt PROPERTY IMPORTED_LOCATION "${FMT_LIBRARY}")
+endif()
+
 set(TORCH_PYTHON_LINK_LIBRARIES
     torch_library
     shm
-    fmt::fmt-header-only)
+	fmt)
 
 set(TORCH_PYTHON_COMPILE_DEFINITIONS)
 
--- a/caffe2/CMakeLists.txt
+++ b/caffe2/CMakeLists.txt
@@ -586,6 +586,12 @@
       VERSION ${TORCH_VERSION} SOVERSION ${TORCH_SOVERSION})
 endif()
 torch_compile_options(torch_cpu)  # see cmake/public/utils.cmake
+if(NOT FMT_LIBRARY)
+	add_library(fmt STATIC IMPORTED)
+	find_library(FMT_LIBRARY fmt)
+	set_property(TARGET fmt PROPERTY IMPORTED_LOCATION "${FMT_LIBRARY}")
+endif()
+target_link_libraries(torch_cpu PRIVATE fmt)
 
 if(USE_LLVM AND LLVM_FOUND)
   llvm_map_components_to_libnames(LLVM_LINK_LIBS
